apiVersion: v1
items:
- apiVersion: v1
  data:
    HDFS_MASTER_SERVICE: hdfs-master
    HDOOP_YARN_MASTER: yarn-master
    core-site.xml: "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n    <?xml-stylesheet
      type=\"text/xsl\" href=\"configuration.xsl\" rel=\"external nofollow\"  rel=\"external
      nofollow\" ?>\n    <configuration>\n        <property>\n            <name>fs.defaultFS</name>\n
      \           <value>hdfs://hdfs-master:9000</value>\n        </property>\n        <property>\n
      \           <name>dfs.namenode.rpc-bind-host</name>\n            <value>0.0.0.0</value>\n
      \       </property>\n        <property>\n\t  <name>hadoop.security.token.service.use_ip</name>\n\t
      \ <value>false</value>\n\t</property>\n        <property>\n          <name>hadoop.http.staticuser.user</name>\n
      \         <value>root</value>\n        </property>\n        <property>\n          <name>hadoop.proxyuser.root.groups</name>\n
      \         <value>*</value>\n        </property>\n        <property>\n          <name>hadoop.proxyuser.root.hosts</name>\n
      \         <value>*</value>\n        </property>\n        <property>\n          <name>net.topology.script.file.name</name>\n
      \         <value>/opt/hadoop/etc/hadoop/rack_topology.sh</value>\n        </property>\n
      \   </configuration>"
    hadoop-env.sh: |-
      export HDFS_DATANODE_USER=root
      export HDFS_NAMENODE_USER=root
      export HDFS_SECONDARYNAMENODE_USER=root
      export JAVA_HOME=/usr/local/openjdk-8
      export HADOOP_OS_TYPE=${HADOOP_OS_TYPE:-$(uname -s)}
      export HADOOP_OPTS="-Djava.library.path=${HADOOP_HOME}/lib/native"
    hdfs-site.xml: |-
      <?xml version="1.0" encoding="UTF-8"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl" rel="external nofollow"  rel="external nofollow" ?>
          <configuration>
              <property>
                  <name>dfs.namenode.http-address</name>
                  <value>0.0.0.0:9870</value>
              </property>
              <property>
                  <name>dfs.namenode.name.dir</name>
                  <value>file:///opt/hadoop/hdfs/name</value>
              </property>
              <property>
                  <name>dfs.datanode.data.dir</name>
                  <value>file:///opt/hadoop/hdfs/data</value>
              </property>
              <property>
                  <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
                  <value>false</value>
              </property>
              <property>
                  <name>dfs.replication</name>
                  <value>3</value>
              </property>
              <property>
                <name>dfs.permissions</name>
                <value>false</value>
              </property>
              <property>
                 <name>dfs.data.dir</name>
                 <value>/hdfs/data</value>
              </property>
      </configuration>
    rack_topology.data: |-
      datanode-0 /rack00
      datanode-1 /rack01
      datanode-2 /rack02
    rack_topology.sh: |-
      #!/bin/bash
      echo -n "/rack-01"
    yarn-site.xml: "<?xml version=\"1.0\"?>\n<configuration>\n    <property>\n        <name>yarn.nodemanager.aux-services</name>\n
      \       <value>mapreduce_shuffle</value>\n    </property>\n    <property>\n
      \       <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>\n
      \       <value>org.apache.hadoop.mapred.ShuffleHandler</value>\n    </property>\n
      \   <property>\n        <name>yarn.resourcemanager.hostname</name>\n        <value>yarn-master</value>\n
      \   </property>\n\t<property>\n        <name>yarn.resourcemanager.bind-host</name>\n
      \       <value>0.0.0.0</value>\n    </property>\n</configuration>"
  kind: ConfigMap
  metadata:
    name: hadoop-conf
    namespace: hadoop
kind: List
