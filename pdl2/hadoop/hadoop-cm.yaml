apiVersion: v1
items:
- apiVersion: v1
  data:
    HDFS_MASTER_SERVICE: hdfs-master
    HDOOP_YARN_MASTER: yarn-master
    core-site.xml: |-
      <?xml version="1.0" encoding="UTF-8"?>
      <?xml-stylesheet type="text/xsl" href="configuration.xsl" rel="external nofollow"  rel="external nofollow" ?>
      <configuration>
          <property>
            <name>fs.defaultFS</name>
            <value>hdfs://hdfs-master:9000</value>
          </property>
          <property>
            <name>dfs.namenode.rpc-bind-host</name>
            <value>0.0.0.0</value>
          </property>
          <property>
            <name>hadoop.security.token.service.use_ip</name>
            <value>false</value>
          </property>
          <property>
            <name>hadoop.http.staticuser.user</name>
            <value>root</value>
          </property>
          <property>
            <name>hadoop.proxyuser.root.groups</name>
            <value>*</value>
          </property>
          <property>
            <name>hadoop.proxyuser.root.hosts</name>
            <value>*</value>
          </property>
          <property>
            <name>net.topology.script.file.name</name>
            <value>/opt/hadoop/etc/hadoop/rack_topology.sh</value>
          </property>
        </configuration>
    hadoop-env.sh: |-
      export HDFS_DATANODE_USER=root
      export HDFS_NAMENODE_USER=root
      export HDFS_SECONDARYNAMENODE_USER=root
      export JAVA_HOME=/usr/local/openjdk-8
      export HADOOP_OS_TYPE=${HADOOP_OS_TYPE:-$(uname -s)}
      export HADOOP_OPTS="-Djava.library.path=${HADOOP_HOME}/lib/native"
    hdfs-site.xml: |-
      <?xml version="1.0" encoding="UTF-8"?>
          <?xml-stylesheet type="text/xsl" href="configuration.xsl" rel="external nofollow"  rel="external nofollow" ?>
          <configuration>
              <property>
                  <name>dfs.namenode.http-address</name>
                  <value>0.0.0.0:9870</value>
              </property>
              <property>
                  <name>dfs.namenode.name.dir</name>
                  <value>file:///opt/hadoop/hdfs/name</value>
              </property>
              <property>
                  <name>dfs.datanode.data.dir</name>
                  <value>file:///opt/hadoop/hdfs/data</value>
              </property>
              <property>
                  <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
                  <value>false</value>
              </property>
              <property>
                  <name>dfs.replication</name>
                  <value>3</value>
              </property>
              <property>
                <name>dfs.permissions</name>
                <value>false</value>
              </property>
              <property>
                 <name>dfs.data.dir</name>
                 <value>/hdfs/data</value>
              </property>
      </configuration>
    rack_topology.data: |-
      datanode-0 /rack00
      datanode-1 /rack01
      datanode-2 /rack02
    rack_topology.sh: |-
      #!/bin/bash
      echo -n "/rack-01"
    yarn-site.xml: |-
      <?xml version="1.0"?>
      <configuration>
        <property>
          <name>yarn.nodemanager.aux-services</name>
          <value>mapreduce_shuffle</value>
        </property>
        <property>
          <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
          <value>org.apache.hadoop.mapred.ShuffleHandler</value>
        </property>
        <property>
          <name>yarn.resourcemanager.hostname</name>
          <value>yarn-master</value>
        </property>
        <property>
          <name>yarn.resourcemanager.bind-host</name>
          <value>0.0.0.0</value>
        </property>
      </configuration>
  kind: ConfigMap
  metadata:
    name: hadoop-conf
    namespace: hadoop
kind: List
